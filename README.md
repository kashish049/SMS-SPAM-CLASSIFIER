ğŸ“© SMS Spam Classifier â€” Machine Learning & NLP Project

A classical machine learningâ€“based SMS spam detection system built to classify messages as Spam or Ham (Not Spam) using natural language preprocessing and multiple ML models.
This project demonstrates end-to-end ML workflow, including data cleaning, feature extraction, model training, evaluation, and comparison.

ğŸ“Œ Resume-aligned focus: NLP preprocessing, ML model training, precisionâ€“recall analysis, and evaluation â€” no black-box deep learning.

ğŸ§  Problem Statement

SMS spam causes financial fraud and poor user experience.
The goal of this project is to automatically classify SMS messages using machine learning and NLP techniques to reduce spam exposure.

ğŸ› ï¸ Tech Stack

Language: Python

Libraries: Scikit-learn, NLTK, NumPy, Pandas, Matplotlib

ML Models:

Support Vector Machine (SVM)

K-Nearest Neighbors (KNN)

Multilayer Perceptron (MLP)

Concepts: NLP, Feature Engineering, Model Evaluation

âœ¨ Key Features

End-to-end ML pipeline for text classification

Text preprocessing:

Cleaning & normalization

Tokenization

Stopword removal

Lemmatization

Feature extraction using word-based representations

Multiple model training & comparison

Performance evaluation using:

Accuracy

Precision

Recall

F1-score

Confusion matrix analysis to study false positives/negatives

ğŸ“‚ Project Structure
SMS-SPAM-CLASSIFIER/
â”‚
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ sms_spam_classifier.ipynb   # Complete ML pipeline (Colab notebook)
â”œâ”€â”€ sms_spam_collection.csv     # Dataset


ğŸ“Œ Entire implementation is available in a single notebook for clarity and easy review by recruiters.

âš™ï¸ How It Works (Step-by-Step)
1ï¸âƒ£ Data Preprocessing

Removed punctuation, numbers, and extra spaces

Converted text to lowercase

Tokenized SMS messages

Removed stopwords

Applied lemmatization for word normalization

2ï¸âƒ£ Feature Engineering

Converted cleaned text into numerical vectors suitable for ML models

Focused on interpretable, classical NLP features

3ï¸âƒ£ Model Training

Trained and compared:

SVM â†’ strong margin-based classifier

KNN â†’ distance-based baseline model

MLP â†’ shallow neural network for comparison

4ï¸âƒ£ Model Evaluation

Used trainâ€“test split

Evaluated using precisionâ€“recall trade-offs

Analyzed confusion matrices to understand misclassifications

ğŸ“Š Results & Observations
Model	Accuracy	Key Insight
SVM	~98%	Best balance of precision & recall
KNN	~93%	High precision, lower recall
MLP	~97%	Strong performance, slightly less interpretable

ğŸ“Œ Learning Outcome:
Accuracy alone is insufficient â€” precision and recall matter more in spam detection to avoid false positives.

ğŸ§ª Sample Prediction
message = "Congratulations! You've won a free ticket. Call now!"


Output:

Spam

ğŸ¯ What This Project Demonstrates (For Recruiters)

Strong understanding of NLP fundamentals

Ability to build ML systems from scratch

Experience with model evaluation and trade-off analysis

Clear grasp of classical ML models (often preferred in interviews)

Clean, explainable, and reproducible experimentation

ğŸ“š Dataset

UCI SMS Spam Collection Dataset
Widely used benchmark dataset for NLP and spam detection tasks.

ğŸš€ Future Improvements

Add TF-IDF + n-grams comparison

Hyperparameter tuning

Deploy as a REST API

Add real-time inference demo

ğŸ‘¤ Author

Ashish Kumar

GitHub: https://github.com/kashish049

Email: kashish04945@gmail.com
